[section Tutorials]

`TODO SIMPLIFY, REMOVE NT2 REFERENCE, BE MORE PIECEWISE`

[section Adding new specializations]

At the moment, there is no clear policy of what to put in the modules that defines a particular toolbox.

However, good practice would suggest that if you wish to a add specializations of some functions
for a particular backend or user-defined type, you should do so in a module named after that
backend's name rather than in the module that defines the basic or fully generic versions of that function.

Each file should include the file that define the function that forwards to Boost.Dispatch, and all of its dependencies.
Specializations may then be injected in the `nt2::ext` namespace, using the `NT2_FUNCTION_IMPLEMENTATION` and
other related macros.

Each file is responsible for disabling those specializations if the compiler does not have the necessary support
for them.

[section Example: adding AVX plus]

AVX currently lives across the various base modules associated with each ['sys] toolbox. It could be argued
however that it should live in its own module, but we're going to ignore this for now, and make it live
in =boost.simd.operator=. That module is the same as the =operator= module for all practical purposes,
except it uses the `boost::simd` namespace instead of `nt2`.

Let us take the scenario that we want to add a specialization for the function =plus= on targets that support
AVX (assuming it doesn't already exist).

We therefore create the file

=nt2/modules/boost/simd/operator/include/boost/simd/toolbox/operator/functions/simd/sse/avx/plus.hpp=

[c++]
``
#ifndef BOOST_SIMD_TOOLBOX_OPERATOR_FUNCTIONS_SIMD_SSE_AVX_HPP_INCLUDED
#define BOOST_SIMD_TOOLBOX_OPERATOR_FUNCTIONS_SIMD_SSE_AVX_HPP_INCLUDED

#include <boost/simd/sdk/simd/extensions/sse/avx.hpp> // detect and include AVX intrinsics
#ifdef BOOST_SIMD_HAS_AVX_SUPPORT // we only continue if AVX support is enabled

#include <boost/simd/toolbox/operator/functions/plus.hpp> // include forwarding function and tag definition

namespace boost { namespace simd { namespace ext
{
  BOOST_SIMD_FUNCTION_IMPLEMENTATION(
    boost::simd::tag::plus_, // tag must be fully qualified
    boost::simd::tag::avx_, // function is associated with the avx_ evaluation site (fully qualified too)
    (A0), // sequence of template parameters
    (simd_< float_<A0>, boost::simd::tag::avx_>) // sequence of arguments
    (simd_< float_<A0>, boost::simd::tag::avx_>) // arguments are single-precision AVX (i.e. wrappers of __m256)
  )
  {
    typedef A0 result_type;
    BOOST_SIMD_FUNCTOR_CALL(2) // short for 'inline result_type operator()(A0 const& a0, ...) const'
    {
      result_type const that = { _mm256_add_ps(a0, a1)) };
      return that;
    }
  };

  BOOST_SIMD_FUNCTION_IMPLEMENTATION(
    boost::simd::tag::plus_,
    boost::simd::tag::avx_,
    (A0),
    (simd_< double_<A0>, boost::simd::tag::avx_>) // sequence of arguments
    (simd_< double_<A0>, boost::simd::tag::avx_>) // arguments are double-precision AVX (i.e. wrappers of __m256d)
  )
  {
    typedef A0 result_type;
    BOOST_SIMD_FUNCTOR_CALL(2)
    {
      result_type const that = { _mm256_add_pd(a0, a1)) };
      return that;
    }
  };
} } }

#endif
#endif
``

As you can see, a tag is associated to each function, so as to allow specialization. The __NT2__
naming conventations are that, for a function [^[~foo]], the tag is [^tag::[~foo]_], while for constants
no underscore is appended.

The specialization then defines a function object that must conform to
[@http://www.boost.org/doc/libs/release/libs/utility/utility.htm#result_of the =result_of= protocol].

`boost::simd::tag::avx_` appears several times due to it being both a property of the data and of the
evaluation. In certain situations, you could want to decorelate data and evaluation, which is why that
distinction is made. For example, some AVX instructions apply to SSE registers.

Due to insufficient typing of AVX types, they are wrapped in a POD type, which is why
the `{ }` initialization is necessary in that example.

[endsect] [/ AVX plus ]

[endsect]

[section Adding new functions]

Adding new functions requires defining a tag associated with that function, along with a free
function that will forward to Boost.Dispatch with that tag.

Boost.Dispatch does not support template parameters other than arguments, so template parameters
of the free function must be translated into an argument.

Let us consider we want to add a new function =pow_n<N>(a0)=, that elevates its argument to the compile-time
known power =N=. We also want to allow =pow_n(a0, a1)=.

We'll add that function to the arithmetic toolbox, but only in __NT2__:

=nt2/modules/arithmetic/include/nt2/toolbox/arithmetic/functions/pow_n.hpp=

[c++]
``
#ifndef NT2_TOOLBOX_ARITHMETIC_FUNCTIONS_POW_N_HPP_INCLUDED
#define NT2_TOOLBOX_ARITHMETIC_FUNCTIONS_POW_N_HPP_INCLUDED

#include <nt2/sdk/functor/functor.hpp> // Boost.Dispatch in the NT2 namespace
#include <boost/mpl/int.hpp>

namespace nt2
{
  namespace tag
  {
    struct pow_n_ {}; // tag definition
  }

  /** \brief elevates \c a0 to the compile-time known power \c N. **/
  template<int N, class A0>
  BOOST_FORCEINLINE // function is force inline because it would
                              // never make sense not to inline it
  typename meta::call<tag::pow_n_(A0, boost::mpl::int_<N>)>::type
  pow_n(A0 const& a0)
  {
    return typename make_functor<tag::pow_n_, A0>::type()
      (a0, boost::mpl::int_<N>())
    ;
  }

  /** \brief elevates \c a0 to the power \c a1. **/
  NT2_FUNCTION_IMPLEMENTATION(tag::pow_n_, pow_n, 2) // a ready-made macro exists for
                                                     // this simple case
}

#endif
``

We'll then provide at least a generic implementation in

=nt2/modules/arithmetic/include/nt2/toolbox/arithmetic/functions/generic/pow_n.hpp=
``
#ifndef NT2_TOOLBOX_ARITHMETIC_FUNCTIONS_GENERIC_POW_N_HPP_INCLUDED
#define NT2_TOOLBOX_ARITHMETIC_FUNCTIONS_GENERIC_POW_N_HPP_INCLUDED

#include <nt2/toolbox/arithmetic/functions/pow_n.hpp>
#include <nt2/include/functions/multiplies.hpp>
#include <nt2/include/constants/one.hpp>
#include <nt2/sdk/meta/hierarchy.hpp> // generic hierarchy
#include <nt2/sdk/meta/mpl.hpp>       // mpl_integral hierarchy

namespace nt2 { namespace ext
{
  NT2_FUNCTION_IMPLEMENTATION(
    nt2::tag::pow_n_,
    tag::cpu_,
    (A0)(A1),
    (generic_< arithmetic_<A0> >)
    (generic_< integer_<A1> >)
  )
  {
    typedef A0 result_type;
    NT2_FUNCTOR_CALL(2)
    {
      result_type that = One<result_type>();
      for(int i=0; i != a1; ++i)
        that *= a0;
      return that;
    }
  };
} }

#endif
``

We don't even need to give a version for MPL integrals, since MPL integrals can
behave as integers as well.

[caution This is just an example, and might not be a very interesting function to add.]

[endsect]

[section Dealing with ASTs]
[endsect]

[section Adding new types]

New basic types should be defined in the tree under [^nt2/sdk/[~some-directory]],
and will need to be associated to a hierarchy to benefit from the dispatching system.

[endsect]

[endsect]
