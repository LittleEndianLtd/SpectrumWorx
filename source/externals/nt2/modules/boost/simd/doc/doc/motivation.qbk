[section Context and Motivation]
In this section, we will go over a simple example of what SIMD programming requires
if done by hand. It will highlight the main difficulties of SIMD programming and
what we should aim at providing to simplify this task.

[section Writing a SIMD kernel]
Here is a simple example. Let's consider a simple addition-multiplication kernel (usually known as AXPY) and
let's write it using Intel's SSE2 instructions set for both single and double precision real.

``
#include <emmintrin.h>

__m128 axpy( __m128 x, __m128 y, __m128 a)
{
  return _mm_add_ps ( _mm_mul_ps(a, x), y)) ;
}

__m128d axpy( __m128d x, __m128d y, __m128d a)
{
  return _mm_add_pd( _mm_mul_pd(a, x), y) ) ;
}
``

So, we first need to include the SSE specific header file `emmintrin.h`. Then
we have access to two new types : `__m128` and `__m128d` which represents a SIMD
vector of `float` and a SIMD vector of `double`. We then computes `a*x+y` using
the intrinsic function `_mm_add_p?` and `_mm_mul_p?`. Note how these function are
using C style overloading based on name instead of classic type-based overloading,
thus requiring us to write the function twice. At this point, one may consider
that writing such code, if a bit inelegant, is not that hard. Now, consider you
need to port this code over some PowerPC architecture featuring the Altivec extension.
The code now looks like:

``
#include <altivec.h>

vector float axpy( vector float x, vector float y, vector float a)
{
  return vec_madd(a,x,y);
}
``

In Altivec, we found a `vec_madd` instruction performing the `a*x+y` operation
at once. However, there is no support for `double` on all Altivec flavor so
we're stuck with the `float` version only. Note how the SIMD register type is
defined. Contrary to SSE where a new type is provided, the SIMD quality of a
variable in Altivec is specified through a type qualifier like notation.

We could also have a look at ARM NEON way to perform this computation, to find
out a new set of types and functions or discover that some Intel instructions
set has a `vec_madd` like operations but on some types only. The list of
differences goes on and on and could easily fill pages.
[endsect]

[section Processing data]
Our mission is not complete. We know have to apply this kernel on actual data. The interest of SIMD lies in the
fact we can apply this large register sized operation to a lot of data. However, most SIMD extensions require
data in memory to be aligned on an adress which is a multiple of the register size. This means SSE or Altivec
codes need theirs data aligned on 16 bytes. Now, we need to have a way to allocate and deallocate a block of
memory with some alignment constraints. In a very similar fashion than for the actual code, we found out that
aligned memory allocation is, this time, a system specific task. Most POSIX system provide `posix_memalign` function
that work in a way similar to `malloc` but take an additional parameter specifying the alignment. On Windows,
the SSE header provide a `_mm_alloc` function. Finally, on PowerPC system, the regular `new` is already providing
memory aligned over Altivec constraints. Some `#ifdef` later, we now have our `aligned_alloc` function or, for the
brave one, a `aligned_allocator` class that could be used in standard containers.

We're set ! Well, almost. There is nothing that allow us to iterate over a block of `T` as if it was some `vector T`
or `__m128?`. We have to use either casts or the extension specific functions to load and store data between memory
and SIMD registers. Additionally, we need to generate a vector full of `a`. The code then look like :

``
#include "axpy.h"
#include "aligned_alloc.h"

void axpy(float* bx, float* ex,, float* by, float a)
{
  // Retrieve SIMD compatible pointers
  __m128* vbx = static_cast<__m128*>(bx);
  __m128* vex = static_cast<__m128*>(ex);
  __m128* vby = static_cast<__m128*>(by);

  // Generate a vector full of a
  __m128 va = _mm_set1_ps(a);

  while(vbx != vex)
  {
    *vby = axpy(*vbx,*vby,a);
    ++bx; ++by;
  }
}
``

Reader can infer the kind of rework to do for adapting this code to Altivec.
[endsect]

[section About auto-vectorization]
[endsect]

[section Objectives]
This short abridged example shows only a few of the pitfalls that may arise
while writing SIMD code. More can actually happens:

* Additional, system-level tasks like aligning memory are often required;
* Most SIMD instructions are usually asymmetric, providing only so much functions
  for, sometimes, very few types;
* Efficient SIMD code writing may require complex, bit-level algorithms thus
  making the code intent less clear;
* Non trivial arithmetic functions are often lacking or give low precision.
* Optimal code may change from extension to extension. the multiply-add example
  here is a classic one. Ideally one should be able to write `a*b+c` and have
  the library decide which variant to use depending on type and architecture;

[endsect]


[endsect]
